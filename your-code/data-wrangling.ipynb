{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project week two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original description of the dataset is: \n",
    "\n",
    "*\"There are some big plane crashes recently. I want to know more about the crashes. For very first step, I need to collect data from somewhere, then I found http://www.planecrashinfo.com/database.htm You guys can pull new data from planecrashinfo.com by using https://github.com/hocnx/planecrashinfo_scraping\"*\n",
    "\n",
    "And the description of the column headers:\n",
    "\n",
    "1. date:    Date of accident,  in the format - January 01, 2001\n",
    "2. time:    Local time, in 24 hr. format unless otherwise specified\n",
    "3. location: location information\n",
    "4. Airline/Op:  Airline or operator of the aircraft\n",
    "5. flight_no:   Flight number assigned by the aircraft operator\n",
    "6. route:   Complete or partial route flown prior to the accident\n",
    "7. ac_type:     Aircraft type\n",
    "8. registration:    ICAO registration of the aircraft\n",
    "9. cn_ln:   Construction or serial number / Line or fuselage number\n",
    "10. aboard:  Total aboard (passengers / crew)\n",
    "11. fatalities:  Total fatalities aboard (passengers / crew)\n",
    "12. ground:  Total killed on the ground\n",
    "13. summary:     Brief description of the accident and cause if known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading dataset file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data stored on a csv file, so we use pandas utilities in order to read the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_crashes_data = pd.read_csv('plane_crash_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A briefly view of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plane_crashes_data.tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first attempt to check missing values with 'isna()' didn't work, because all the missing values were replace with '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_col = plane_crashes_data.isna().sum()\n",
    "nulls_col[nulls_col > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to search all the '?' in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missings_data = (plane_crashes_data == '?').sum()\n",
    "print('Missing values:')\n",
    "missings_data[missings_data > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we were able to see that there are not missing values for: [date,aboard,fatalities] but in the case of \"aboard\" and \"fatalities\" it doesn't mean that we don't have problems because this columns contain a string (it is a value) where it can contain missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we make a little more complex search in that columns\n",
    "check_aboard_miss = lambda x: True if len(re.findall(r'[?]',str(x))) > 0 else False\n",
    "aboard_missings = plane_crashes_data['aboard'].apply(check_aboard_miss)\n",
    "fatalities_missings = plane_crashes_data['fatalities'].apply(check_aboard_miss)\n",
    "abo_fatal_missing = pd.DataFrame()\n",
    "abo_fatal_missing['aboard_m'] = aboard_missings\n",
    "abo_fatal_missing['fatalities_m'] = fatalities_missings\n",
    "missing_abo_fatal = (abo_fatal_missing == False).sum()\n",
    "print('Missing values:')\n",
    "missing_abo_fatal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can see that we have: \n",
    "1. 544 complete info registers for aboard\n",
    "2. 561 complete info for fatalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to clean each column using the order of appearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the date of the crash, but it is format in a single string with the \"Month day, year\" structure but\n",
    "I considered that it is more useful to have three columns with each element of the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search in the date column all the letters to obtain the Month\n",
    "months = [''.join(re.findall(r'[A-Za-z]',plane_crashes_data['date'][da])) for da in range(len(plane_crashes_data['date']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in the date column the group of two digits for the day\n",
    "days = [''.join(re.findall(r'\\b\\d{2}\\b',plane_crashes_data['date'][da])) for da in range(len(plane_crashes_data['date']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in the date column the group of four digits for the day\n",
    "years = [''.join(re.findall(r'\\b\\d{4}\\b',plane_crashes_data['date'][da])) for da in range(len(plane_crashes_data['date']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the time column we don't have a homogenus format so we check the formats that exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_crashes_data['time'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not information about the 'c' character in the time so, we create a new column with this value.\n",
    "Note: Investigate the meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_c_char = lambda x: True if len(re.findall(r'[c]',str(x))) > 0 else False\n",
    "char_unknow = plane_crashes_data['time'].apply(check_c_char)\n",
    "char_unknow = char_unknow.replace(True, value='c')\n",
    "char_unknow = char_unknow.replace(False, value='not c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I decided to split this column into two new columns for time_hour and time_minutes, in order to facilitate further filtering tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_time_for = lambda x: True if len(re.findall(r'[:]',str(x))) > 0 else False\n",
    "\n",
    "#If we have a different format than \"hh:mm\" we reformat and if we have the 'c' character we drop it\n",
    "def reformat(x):\n",
    "    if check_c_char(x):\n",
    "        x = x.replace(\"c\",\" \")\n",
    "    if not check_time_for(x) and x != '?':\n",
    "        x = x[:2] + ':' + x[2:]\n",
    "    return x\n",
    "\n",
    "get_hour_time = lambda x: x.replace(' ','')[:2] if x != '?' else x\n",
    "get_minutes_time = lambda x: x.replace(' ','')[3:] if x != '?' else x\n",
    "\n",
    "new_times = plane_crashes_data['time'].apply(reformat)\n",
    "time_hour = new_times.apply(get_hour_time)\n",
    "time_minutes = new_times.apply(get_minutes_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the location column we can see that in the major we have a \"region,Country\" structure so we try to split the values using commas and identify which one is the country. Also we can identify that when the tragedy happen in the United States they use a \"region, State\" structure so we also have to identify if the element in the column belongs to the United States, for that I create a csv with the Unite States states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load states.csv\n",
    "states = pd.read_csv('states.csv')\n",
    "states = states['state'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lb = lambda x: x.split(',')\n",
    "check_if_state = lambda x: True if x in states else False\n",
    "\n",
    "region_country = pd.DataFrame(plane_crashes_data['location'].apply(split_lb))\n",
    "\n",
    "def who_is_country(li_country):\n",
    "    temp = []\n",
    "    for i in li_country:\n",
    "        if len(i) > 1:\n",
    "            if i[0] != ' ':\n",
    "                if check_if_state(i):\n",
    "                    temp.append('United States')\n",
    "                else:\n",
    "                    temp.append(i)\n",
    "            else:\n",
    "                if check_if_state(i[1:]):\n",
    "                    temp.append('United States')\n",
    "                else:\n",
    "                    temp.append(i[1:])\n",
    "        else:\n",
    "            return li_country\n",
    "    return temp[-1]\n",
    "countries = region_country['location'].apply(who_is_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a lot of kinds in the operator column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(plane_crashes_data['operator'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to get a little more homogenus column incorporating each operator in a same category if the word 'Military' is in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_militar = lambda x: 'Military' if len(re.findall(r'(?:Military|Forces?|Fuerzas?|Army)',x,re.I)) > 0 else x\n",
    "new_operators = plane_crashes_data['operator'].apply(check_is_militar)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A category for Government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_gover = lambda x: 'Government' if len(re.findall(r'(?:Government|Gobierno)',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_is_gover)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also if the word 'taxi' is in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_taxi = lambda x: 'Taxi' if len(re.findall(r'Taxi',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_is_taxi)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also there is a small category of operators with the word 'Helicopters' is in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_is_helicopter = lambda x: 'Helicopter' if len(re.findall(r'Helicopters?',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_is_helicopter)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the major of the comercial operators contain the word 'Airlines' or 'Airways' in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_airline_airways = lambda x: 'Airlines-Airways operator' if len(re.findall(r'(?:Airlines?|Airways?|Air lines?|Aerolineas?|Lineas?)',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_airline_airways)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small category of 'Services' operators,it could be the same than a commercial 'Airlines-Airways', but we keep with a different category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_service = lambda x: 'Services' if len(re.findall(r'(?:Services?|Servicios?)',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_service)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small category of 'Transport' operators,it could be the same than a 'Services' category, but we keep with a different category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_transport = lambda x: 'Transport' if len(re.findall(r'Transports?',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_transport)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A category for 'Companies' operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_transport = lambda x: 'Company' if len(re.findall(r'(?:Companys?|Compañias?|\\sInc.)',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_transport)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A category for 'Air Company' operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_transport = lambda x: 'Air' if len(re.findall(r'Air?',x,re.I)) > 0 else x\n",
    "new_operators = new_operators.apply(check_transport)\n",
    "print(len(set(new_operators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally if the operator is not in one of the categories defined by me, I put on a 'No category' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_operators_list = ['Military','Government','Taxi','Helicopter','Airlines-Airways operator','Services','Transport','Company','Air']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_has_category = lambda x: x if x in new_operators_list else 'No category'\n",
    "category_operator = new_operators.apply(check_has_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(plane_crashes_data['route'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a lot of different routes, but in this case there are a lot of variations \"Origin-destiny\",\"Origin-Scale-Destiny\" and also the names has '-' character what makes so complicated try to clean this row, so I didn't change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aircraft type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ac_type = [i.split(' ') for i in plane_crashes_data['ac_type'].tolist()]\n",
    "words_ac_type = [i for x in words_ac_type for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words_ac = {k:words_ac_type.count(k) for k in set(words_ac_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tups = sorted(freq_words_ac.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Aircraft type I just identifided the categories: ['Boeing','Douglas','Lockheed','Cessna','Antonov','Ilyushin','Piper','Fokker'], in order to get a new homogenus column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_boeing = lambda x: 'Boeing' if len(re.findall(r'boeing',x,re.I)) > 0 else x\n",
    "check_lockheed = lambda x: 'Lockheed' if len(re.findall(r'lockheed',x,re.I)) > 0 else x\n",
    "check_douglas = lambda x: 'Douglas' if len(re.findall(r'boeing',x,re.I)) > 0 else x\n",
    "check_cessna = lambda x: 'Cessna' if len(re.findall(r'lockheed',x,re.I)) > 0 else x\n",
    "check_antonov = lambda x: 'Antonov' if len(re.findall(r'boeing',x,re.I)) > 0 else x\n",
    "check_ilyushin = lambda x: 'Ilyushin' if len(re.findall(r'lockheed',x,re.I)) > 0 else x\n",
    "check_piper = lambda x: 'Piper' if len(re.findall(r'boeing',x,re.I)) > 0 else x\n",
    "check_fokker = lambda x: 'Fokker' if len(re.findall(r'lockheed',x,re.I)) > 0 else x\n",
    "\n",
    "new_ac_type = plane_crashes_data['ac_type'].apply(check_boeing)\n",
    "new_ac_type = new_ac_type.apply(check_lockheed)\n",
    "new_ac_type = new_ac_type.apply(check_douglas)\n",
    "new_ac_type = new_ac_type.apply(check_cessna)\n",
    "new_ac_type = new_ac_type.apply(check_antonov)\n",
    "new_ac_type = new_ac_type.apply(check_ilyushin)\n",
    "new_ac_type = new_ac_type.apply(check_piper)\n",
    "new_ac_type = new_ac_type.apply(check_fokker)\n",
    "\n",
    "new_ac_list = ['Boeing','Douglas','Lockheed','Cessna','Antonov','Ilyushin','Piper','Fokker']\n",
    "check_ac_has_category = lambda x: x if x in new_ac_list else 'No category'\n",
    "category_ac_type = new_ac_type.apply(check_ac_has_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight number, Registration and Construction numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this three columns we can obtain few information in our analysis because these are numbers derivate from the country or unique numbers for identification of the flights and planes. So I decided to drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_remove = ['flight_no','registration','cn_ln']\n",
    "plane_crashes_data = plane_crashes_data.drop(columns_remove,axis=1)\n",
    "plane_crashes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aboard and Fatalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this two we have identifided the missing values but the major of times that missing values refers to the information about how many of the tripulation were passenger or crew. So I extracted the value of total people aboard and the fatalities, that are the number out of the parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_out_par = lambda x: x[:x.index('(')].replace(' ','') if x != '?' else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_out_par('19   (passengers:? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboard_total = plane_crashes_data['aboard'].apply(extract_out_par)\n",
    "fatalities_total = plane_crashes_data['fatalities'].apply(extract_out_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this column we have just a few amount of missing values (52) so I decided to fill them with zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plane_crashes_data['ground'] == '?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_miss = lambda x: 0 if x == '?' else x\n",
    "ground_fill = plane_crashes_data['ground'].apply(change_miss)\n",
    "(ground_fill == '?').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this modifications we add the new columns to the original dataframe and then we order all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_remove = ['date','time','location','aboard','fatalities','ground']\n",
    "plane_crashes_data = plane_crashes_data.drop(columns_remove,axis=1)\n",
    "plane_crashes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_crashes_data['month'] = months\n",
    "plane_crashes_data['day'] = days\n",
    "plane_crashes_data['year'] = years\n",
    "\n",
    "plane_crashes_data['time_hour'] = time_hour\n",
    "plane_crashes_data['time_minutes'] = time_minutes\n",
    "\n",
    "plane_crashes_data['char_unknow'] = char_unknow\n",
    "\n",
    "plane_crashes_data['country'] = countries\n",
    "\n",
    "plane_crashes_data['category_operator'] = category_operator\n",
    "plane_crashes_data['category_ac_type'] = category_ac_type\n",
    "plane_crashes_data['aboard_people'] = aboard_total\n",
    "plane_crashes_data['fatalities_total'] = fatalities_total\n",
    "\n",
    "plane_crashes_data['ground_deads'] = ground_fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos\n",
    "column_order = ['month','day','year','char_unknow','time_hour','time_minutes','operator','category_operator','ac_type','category_ac_type','country','route','aboard_people','fatalities_total','ground_deads','summary']\n",
    "plane_crash_clean = plane_crashes_data[column_order]\n",
    "plane_crash_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I decided to change all the missing values (in this case '?') for the 'Unknown' string value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_to_unknown = lambda x: 'Unknown' if str(x) == '?' else x\n",
    "for i in plane_crash_clean.columns:\n",
    "    plane_crash_clean[i] = plane_crash_clean[i].apply(change_to_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plane_crash_clean.to_csv('data_plane_clean.csv')\n",
    "plane_crash_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
